{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at DistilBERT_Final_model/DistilBERT_with_LRDecay_model_5e-5 were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at DistilBERT_Final_model/DistilBERT_with_LRDecay_model_5e-5 and are newly initialized: ['dropout_59']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT model and tokenizer loaded successfully!\n",
      "VGG16 model loaded successfully!\n",
      "Text LabelEncoder loaded successfully!\n",
      "Image LabelEncoder loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from transformers import TFDistilBertForSequenceClassification, DistilBertTokenizer\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Pre-trained Models\n",
    "# Load the DistilBERT model and Tokenizer from the saved folder (when saved using huggingface) (text model, saved in Transformers format)\n",
    "text_model = TFDistilBertForSequenceClassification.from_pretrained('DistilBERT_Final_model/DistilBERT_with_LRDecay_model_5e-5')\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('DistilBERT_Final_model/DistilBERT_with_LRDecay_tokenizer_5e-5')\n",
    "print(\"DistilBERT model and tokenizer loaded successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the VGG16 model saved as .keras (image model, saved in .keras format)\n",
    "image_model = load_model('my_model_VGG16_reducelr_1e-5.keras')\n",
    "print(\"VGG16 model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Label Encoders for both text and image classifier\n",
    "# Text classification label encoder\n",
    "text_label_encoder = joblib.load('text_label_encoder.joblib')\n",
    "print(\"Text LabelEncoder loaded successfully!\")\n",
    "\n",
    "# Image classification label encoder\n",
    "with open('class_indices_my_model_VGG16.json', 'r') as f:\n",
    "    image_class_indices = json.load(f)\n",
    "    image_label_decoder = {v: k for k, v in image_class_indices.items()}  # Reverse mapping\n",
    "print(\"Image LabelEncoder loaded successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Preprocessing Functions for text\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess text for the DistilBERT model.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"tf\", padding=True, truncation=True, max_length=128)\n",
    "    return inputs['input_ids'], inputs['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Preprocessing Functions for image\n",
    "def preprocess_image(img_path):\n",
    "    \"\"\"Preprocess image for the VGG16 model.\"\"\"\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "    img = image.load_img(img_path, target_size=(224, 224)) #resize the image\n",
    "    img_array = image.img_to_array(img)  #image to array( to height, width and color channel)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension (converts 3 dim to 4 dim (batchsize, height, width, color channel))\n",
    "    img_array = preprocess_input(img_array) #Normalize the image (Channel layers/255)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Late Fusion with Weighted Soft Voting\n",
    "def late_fusion_weighted_soft_voting(text_input, img_path, text_label_encoder, image_label_decoder, text_weight=0.61, image_weight=0.39):\n",
    "    \"\"\"\n",
    "    Perform late fusion using weighted soft voting with probability outputs from both models.\n",
    "    \n",
    "    Args:\n",
    "        text_input (str): Text input for the DistilBERT model.\n",
    "        img_path (str): Path to the image for the VGG16 model.\n",
    "        text_label_encoder (LabelEncoder): The saved label encoder for the text model.\n",
    "        image_label_decoder (dict): Decoder for the image model class indices.\n",
    "        text_weight (float): Weight for the text model predictions.\n",
    "        image_weight (float): Weight for the image model predictions.\n",
    "    \n",
    "    Returns:\n",
    "        Final predicted class label after weighted soft voting fusion.\n",
    "    \"\"\"\n",
    "    # Preprocess text inputs\n",
    "    text_ids, text_mask = preprocess_text(text_input)\n",
    "    img_array = preprocess_image(img_path)\n",
    "    \n",
    "    # Get probability predictions from each model\n",
    "    text_logits = text_model(text_ids, attention_mask=text_mask).logits.numpy() #generate logits (raw score before softmax from text model)\n",
    "    text_probs = np.exp(text_logits) / np.sum(np.exp(text_logits), axis=1, keepdims=True)  # Softmax conversion\n",
    "\n",
    "    # Preprocess image inputs\n",
    "    image_probs = image_model.predict(img_array)\n",
    "\n",
    "    # Apply weights to the probabilities\n",
    "    weighted_text_probs = text_probs * text_weight\n",
    "    weighted_image_probs = image_probs * image_weight\n",
    "\n",
    "    # Combine the weighted probabilities\n",
    "    combined_probs = weighted_text_probs + weighted_image_probs\n",
    "\n",
    "    # Get final class index with maximum probability\n",
    "    final_class = np.argmax(combined_probs, axis=1)[0]\n",
    "    \n",
    "    # Decode the final class index to original labels\n",
    "    final_label = text_label_encoder.inverse_transform([final_class])[0]\n",
    "\n",
    "    return final_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step\n",
      "Final Predicted Class: 10\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "text_input = \"oliva\"\n",
    "img_path = \"C:/Users/User/OneDrive - ingenium digital diagnostics GmbH/Desktop/DataScientest/Rakuten project/images/images/image_train/image_1325918866_product_4239126071.jpg\"  # Replace with the path to your image\n",
    "final_prediction = late_fusion_weighted_soft_voting(text_input, img_path, text_label_encoder, image_label_decoder, text_weight=0.61, image_weight=0.39)\n",
    "print(f\"Final Predicted Class: {final_prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
