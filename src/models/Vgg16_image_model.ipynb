{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_path</th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "      <th>prdtypecode</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>image_1000076039_product_580161.jpg</td>\n",
       "      <td>C:/Users/User/OneDrive - ingenium digital diag...</td>\n",
       "      <td>580161</td>\n",
       "      <td>1000076039</td>\n",
       "      <td>10</td>\n",
       "      <td>10 (Used books)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>image_1000089455_product_348990858.jpg</td>\n",
       "      <td>C:/Users/User/OneDrive - ingenium digital diag...</td>\n",
       "      <td>348990858</td>\n",
       "      <td>1000089455</td>\n",
       "      <td>2280</td>\n",
       "      <td>2280 (Used Newspapers and magazines)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>image_1000092894_product_353108104.jpg</td>\n",
       "      <td>C:/Users/User/OneDrive - ingenium digital diag...</td>\n",
       "      <td>353108104</td>\n",
       "      <td>1000092894</td>\n",
       "      <td>2403</td>\n",
       "      <td>2403 (Books, comics, and magazines)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>image_1000093804_product_343306951.jpg</td>\n",
       "      <td>C:/Users/User/OneDrive - ingenium digital diag...</td>\n",
       "      <td>343306951</td>\n",
       "      <td>1000093804</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160 (Board games and role-playing games)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>image_1000095646_product_344209267.jpg</td>\n",
       "      <td>C:/Users/User/OneDrive - ingenium digital diag...</td>\n",
       "      <td>344209267</td>\n",
       "      <td>1000095646</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160 (Board games and role-playing games)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                              image_name  \\\n",
       "0           0     image_1000076039_product_580161.jpg   \n",
       "1           1  image_1000089455_product_348990858.jpg   \n",
       "2           2  image_1000092894_product_353108104.jpg   \n",
       "3           3  image_1000093804_product_343306951.jpg   \n",
       "4           4  image_1000095646_product_344209267.jpg   \n",
       "\n",
       "                                          image_path  productid     imageid  \\\n",
       "0  C:/Users/User/OneDrive - ingenium digital diag...     580161  1000076039   \n",
       "1  C:/Users/User/OneDrive - ingenium digital diag...  348990858  1000089455   \n",
       "2  C:/Users/User/OneDrive - ingenium digital diag...  353108104  1000092894   \n",
       "3  C:/Users/User/OneDrive - ingenium digital diag...  343306951  1000093804   \n",
       "4  C:/Users/User/OneDrive - ingenium digital diag...  344209267  1000095646   \n",
       "\n",
       "   prdtypecode                           product_category  \n",
       "0           10                            10 (Used books)  \n",
       "1         2280       2280 (Used Newspapers and magazines)  \n",
       "2         2403        2403 (Books, comics, and magazines)  \n",
       "3         1160  1160 (Board games and role-playing games)  \n",
       "4         1160  1160 (Board games and role-playing games)  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Excel file\n",
    "df = pd.read_csv('preprocessed_image_train.csv')\n",
    "\n",
    "# Check the first few rows to verify\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84909 entries, 0 to 84908\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   image_path   84909 non-null  object\n",
      " 1   prdtypecode  84909 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df[['image_path', 'prdtypecode']]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>prdtypecode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/User/OneDrive - ingenium digital diag...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/User/OneDrive - ingenium digital diag...</td>\n",
       "      <td>2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/User/OneDrive - ingenium digital diag...</td>\n",
       "      <td>2403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/User/OneDrive - ingenium digital diag...</td>\n",
       "      <td>1160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/User/OneDrive - ingenium digital diag...</td>\n",
       "      <td>1160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path  prdtypecode\n",
       "0  C:/Users/User/OneDrive - ingenium digital diag...           10\n",
       "1  C:/Users/User/OneDrive - ingenium digital diag...         2280\n",
       "2  C:/Users/User/OneDrive - ingenium digital diag...         2403\n",
       "3  C:/Users/User/OneDrive - ingenium digital diag...         1160\n",
       "4  C:/Users/User/OneDrive - ingenium digital diag...         1160"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prdtypecode</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>2671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>3953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>4869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>5045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>2491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>3240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>5073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>4303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>4990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>4760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>4774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>4989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>2589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>10208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>2496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>2761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_path\n",
       "prdtypecode            \n",
       "10                 3116\n",
       "40                 2508\n",
       "50                 1681\n",
       "60                  832\n",
       "1140               2671\n",
       "1160               3953\n",
       "1180                764\n",
       "1280               4869\n",
       "1281               2070\n",
       "1300               5045\n",
       "1301                807\n",
       "1302               2491\n",
       "1320               3240\n",
       "1560               5073\n",
       "1920               4303\n",
       "1940                802\n",
       "2060               4990\n",
       "2220                824\n",
       "2280               4760\n",
       "2403               4774\n",
       "2462               1421\n",
       "2522               4989\n",
       "2582               2589\n",
       "2583              10208\n",
       "2585               2496\n",
       "2705               2761\n",
       "2905                872"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df = df.groupby('prdtypecode').count()\n",
    "count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df['prdtypecode'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['prdtypecode'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 67927, Validation samples: 8491, Test samples: 8491\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training samples: {len(train_df)}, Validation samples: {len(val_df)}, Test samples: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of classes\n",
    "num_classes = len(df['prdtypecode'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prdtypecode</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>2137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>3162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>3895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>1656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>4036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>2592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>4058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>3992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>3808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>3819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>1137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>3991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>2071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>8166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>2209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_path\n",
       "prdtypecode            \n",
       "10                 2493\n",
       "40                 2006\n",
       "50                 1345\n",
       "60                  666\n",
       "1140               2137\n",
       "1160               3162\n",
       "1180                611\n",
       "1280               3895\n",
       "1281               1656\n",
       "1300               4036\n",
       "1301                646\n",
       "1302               1993\n",
       "1320               2592\n",
       "1560               4058\n",
       "1920               3442\n",
       "1940                642\n",
       "2060               3992\n",
       "2220                659\n",
       "2280               3808\n",
       "2403               3819\n",
       "2462               1137\n",
       "2522               3991\n",
       "2582               2071\n",
       "2583               8166\n",
       "2585               1997\n",
       "2705               2209\n",
       "2905                698"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_count = train_df.groupby('prdtypecode').count()\n",
    "train_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2515.814814814815\n",
      "Index([  10, 2705, 1140, 2582,   40, 2585, 1302, 1281,   50, 2462, 2905,   60,\n",
      "       2220, 1301, 1940, 1180],\n",
      "      dtype='int64', name='prdtypecode')\n"
     ]
    }
   ],
   "source": [
    "# Define minority classes (below mean count)\n",
    "mean_count = train_df['prdtypecode'].value_counts().mean()\n",
    "minority_classes = train_df['prdtypecode'].value_counts()[train_df['prdtypecode'].value_counts() < mean_count].index\n",
    "print(mean_count)\n",
    "print(minority_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 2: Handle Class Imbalance with Targeted Augmentation ===\n",
    "import os\n",
    "\n",
    "# Augment and save images for minority classes\n",
    "def augment_minority_classes(df, minority_classes, target_size=(224, 224), augment_count=3, output_dir=\"augmented_data\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Create directory if not exists\n",
    "    \n",
    "    augmenter = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    augmented_data = []\n",
    "    \n",
    "    for class_label in minority_classes:\n",
    "        class_df = df[df['prdtypecode'] == class_label]\n",
    "        for _, row in class_df.iterrows():\n",
    "            img = Image.open(row['image_path']).resize(target_size)\n",
    "            img_array = np.expand_dims(np.array(img), axis=0)\n",
    "            i = 0\n",
    "            for batch in augmenter.flow(img_array, batch_size=1):\n",
    "                # Save augmented image\n",
    "                file_name = f\"aug_{class_label}{i}{os.path.basename(row['image_path'])}\"\n",
    "                file_path = os.path.join(output_dir, file_name)\n",
    "                Image.fromarray((batch[0] * 255).astype('uint8')).save(file_path)\n",
    "                \n",
    "                # Append to augmented data\n",
    "                augmented_data.append({'image_path': file_path, 'prdtypecode': class_label})\n",
    "                i += 1\n",
    "                if i >= augment_count:\n",
    "                    break\n",
    "    \n",
    "    augmented_df = pd.DataFrame(augmented_data)\n",
    "    return augmented_df\n",
    "\n",
    "# Call the function and generate augmented images\n",
    "output_dir = \"augmented_images\"  # Directory to save augmented images\n",
    "augmented_df = augment_minority_classes(train_df, minority_classes, output_dir=output_dir)\n",
    "\n",
    "# Combine augmented data with the original training set\n",
    "train_df = pd.concat([train_df, augmented_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform targeted augmentation for minority classes\n",
    "##augmented_df = augment_minority_classes(train_df, minority_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136825, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine augmented data with the original training set\n",
    "#train_df = pd.concat([train_df, augmented_df])\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('Image_Train_vgg16_new.csv')\n",
    "val_df.to_csv('Image_Val_vgg16_new.csv')\n",
    "test_df.to_csv('Image_Test_vgg16_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_path    136825\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_count = train_df.groupby('prdtypecode').count()\n",
    "train_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation and test data generators\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert prdtypecode to category\n",
    "train_df['prdtypecode'] = train_df['prdtypecode'].astype('category')\n",
    "val_df['prdtypecode'] = val_df['prdtypecode'].astype('category')\n",
    "test_df['prdtypecode'] = test_df['prdtypecode'].astype('category')\n",
    "\n",
    "# Convert category values to string for compatibility\n",
    "train_df['prdtypecode'] = train_df['prdtypecode'].astype(str)\n",
    "val_df['prdtypecode'] = val_df['prdtypecode'].astype(str)\n",
    "test_df['prdtypecode'] = test_df['prdtypecode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 136825 validated image filenames belonging to 27 classes.\n",
      "Found 8491 validated image filenames belonging to 27 classes.\n",
      "Found 8491 validated image filenames belonging to 27 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='image_path',\n",
    "    y_col='prdtypecode', \n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='image_path',\n",
    "    y_col='prdtypecode',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='image_path',\n",
    "    y_col='prdtypecode',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in the training set: 134\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of batches in the train generator\n",
    "num_samples = len(train_generator)  # Number of images in your training dataframe\n",
    "batch_size = 32  # Your batch size\n",
    "\n",
    "num_batches = num_samples // batch_size  # Integer division\n",
    "if num_samples % batch_size != 0:\n",
    "    num_batches += 1  # If there is a remainder, add one more batch\n",
    "\n",
    "print(f\"Number of batches in the training set: {num_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 4: Compute Class Weights ===\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_df['prdtypecode'].astype(int)),\n",
    "    y=train_df['prdtypecode'].astype(int)\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 5: Define the ResNet-50 Model ===\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze the base layers\n",
    "\n",
    "# Add custom layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\OneDrive - ingenium digital diagnostics GmbH\\Desktop\\DataScientest\\Rakuten project\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12360s\u001b[0m 3s/step - accuracy: 0.2914 - loss: 2.3374 - val_accuracy: 0.3883 - val_loss: 2.1297\n",
      "Epoch 2/20\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12249s\u001b[0m 3s/step - accuracy: 0.3308 - loss: 2.1921 - val_accuracy: 0.3896 - val_loss: 2.1262\n",
      "Epoch 3/20\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12246s\u001b[0m 3s/step - accuracy: 0.3329 - loss: 2.1912 - val_accuracy: 0.3904 - val_loss: 2.1225\n",
      "Epoch 4/20\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12233s\u001b[0m 3s/step - accuracy: 0.3321 - loss: 2.1925 - val_accuracy: 0.3912 - val_loss: 2.1204\n",
      "Epoch 5/20\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12205s\u001b[0m 3s/step - accuracy: 0.3305 - loss: 2.1888 - val_accuracy: 0.3918 - val_loss: 2.1182\n",
      "Epoch 6/20\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12257s\u001b[0m 3s/step - accuracy: 0.3301 - loss: 2.1869 - val_accuracy: 0.3912 - val_loss: 2.1160\n",
      "Epoch 7/20\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12229s\u001b[0m 3s/step - accuracy: 0.3344 - loss: 2.1799 - val_accuracy: 0.3928 - val_loss: 2.1134\n",
      "Epoch 8/20\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12176s\u001b[0m 3s/step - accuracy: 0.3316 - loss: 2.1803 - val_accuracy: 0.3932 - val_loss: 2.1112\n",
      "Epoch 9/20\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12195s\u001b[0m 3s/step - accuracy: 0.3333 - loss: 2.1765 - val_accuracy: 0.3935 - val_loss: 2.1091\n",
      "Epoch 10/20\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12245s\u001b[0m 3s/step - accuracy: 0.3345 - loss: 2.1784 - val_accuracy: 0.3939 - val_loss: 2.1072\n",
      "Epoch 11/20\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12235s\u001b[0m 3s/step - accuracy: 0.3337 - loss: 2.1777 - val_accuracy: 0.3951 - val_loss: 2.1052\n",
      "Epoch 12/20\n",
      "\u001b[1m1306/4276\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:13:26\u001b[0m 3s/step - accuracy: 0.3369 - loss: 2.1758"
     ]
    }
   ],
   "source": [
    "# === Step 6: Train the Model ===\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=20,\n",
    "    callbacks = [reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m707s\u001b[0m 3s/step\n"
     ]
    }
   ],
   "source": [
    "# Classification report and confusion matrix\n",
    "predictions = model.predict(test_generator)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.20      0.26       311\n",
      "           1       0.34      0.22      0.27       267\n",
      "           2       0.55      0.75      0.63       395\n",
      "           3       0.00      0.00      0.00        77\n",
      "           4       0.22      0.35      0.27       487\n",
      "           5       0.27      0.01      0.03       207\n",
      "           6       0.46      0.46      0.46       505\n",
      "           7       0.00      0.00      0.00        81\n",
      "           8       0.04      0.01      0.02       249\n",
      "           9       0.49      0.16      0.24       324\n",
      "          10       0.39      0.37      0.38       507\n",
      "          11       0.53      0.68      0.59       431\n",
      "          12       1.00      0.04      0.07        80\n",
      "          13       0.34      0.24      0.28       499\n",
      "          14       0.00      0.00      0.00        82\n",
      "          15       0.39      0.61      0.48       476\n",
      "          16       0.41      0.59      0.49       477\n",
      "          17       0.00      0.00      0.00       142\n",
      "          18       0.36      0.38      0.37       499\n",
      "          19       0.15      0.02      0.04       259\n",
      "          20       0.41      0.79      0.54      1021\n",
      "          21       0.17      0.02      0.04       250\n",
      "          22       0.31      0.69      0.43       276\n",
      "          23       0.00      0.00      0.00        87\n",
      "          24       0.19      0.07      0.10       251\n",
      "          25       0.29      0.02      0.04       168\n",
      "          26       0.39      0.23      0.29        83\n",
      "\n",
      "    accuracy                           0.39      8491\n",
      "   macro avg       0.30      0.26      0.23      8491\n",
      "weighted avg       0.35      0.39      0.33      8491\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\OneDrive - ingenium digital diagnostics GmbH\\Desktop\\DataScientest\\Rakuten project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\OneDrive - ingenium digital diagnostics GmbH\\Desktop\\DataScientest\\Rakuten project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\OneDrive - ingenium digital diagnostics GmbH\\Desktop\\DataScientest\\Rakuten project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model_VGG16_reducelr_1e-5.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class indices saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Save class indices from the train_generator\n",
    "with open('class_indices_my_model_VGG16.json', 'w') as f:\n",
    "    json.dump(train_generator.class_indices, f)\n",
    "\n",
    "print(\"Class indices saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12052s\u001b[0m 3s/step - accuracy: 0.3285 - loss: 2.1991 - val_accuracy: 0.3812 - val_loss: 2.1411 - learning_rate: 0.0000e+00\n",
      "Epoch 2/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12060s\u001b[0m 3s/step - accuracy: 0.3283 - loss: 2.2015 - val_accuracy: 0.3812 - val_loss: 2.1411 - learning_rate: 0.0000e+00\n",
      "Epoch 3/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12030s\u001b[0m 3s/step - accuracy: 0.3274 - loss: 2.2009 - val_accuracy: 0.3812 - val_loss: 2.1411 - learning_rate: 0.0000e+00\n",
      "Epoch 4/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12113s\u001b[0m 3s/step - accuracy: 0.3288 - loss: 2.1979 - val_accuracy: 0.3812 - val_loss: 2.1411 - learning_rate: 0.0000e+00\n",
      "Epoch 5/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12072s\u001b[0m 3s/step - accuracy: 0.3298 - loss: 2.1966 - val_accuracy: 0.3812 - val_loss: 2.1411 - learning_rate: 0.0000e+00\n",
      "Epoch 6/15\n",
      "\u001b[1m 993/4276\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:26:21\u001b[0m 3s/step - accuracy: 0.3264 - loss: 2.2104"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# === Step 6: Train the Model ===\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive - ingenium digital diagnostics GmbH\\Desktop\\DataScientest\\Rakuten project\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive - ingenium digital diagnostics GmbH\\Desktop\\DataScientest\\Rakuten project\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive - ingenium digital diagnostics GmbH\\Desktop\\DataScientest\\Rakuten project\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive - ingenium digital diagnostics GmbH\\Desktop\\DataScientest\\Rakuten project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive - ingenium digital diagnostics GmbH\\Desktop\\DataScientest\\Rakuten project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive - ingenium digital diagnostics GmbH\\Desktop\\DataScientest\\Rakuten project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive - ingenium digital diagnostics GmbH\\Desktop\\DataScientest\\Rakuten project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive - ingenium digital diagnostics GmbH\\Desktop\\DataScientest\\Rakuten project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive - ingenium digital diagnostics GmbH\\Desktop\\DataScientest\\Rakuten project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive - ingenium digital diagnostics GmbH\\Desktop\\DataScientest\\Rakuten project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive - ingenium digital diagnostics GmbH\\Desktop\\DataScientest\\Rakuten project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# === Step 6: Train the Model ===\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=20,\n",
    "    callbacks = [reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m775s\u001b[0m 3s/step - accuracy: 0.5239 - loss: 1.6376\n",
      "Test Accuracy: 0.52\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m722s\u001b[0m 3s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.45      0.47       311\n",
      "           1       0.46      0.52      0.49       267\n",
      "           2       0.78      0.86      0.82       395\n",
      "           3       0.46      0.08      0.13        77\n",
      "           4       0.35      0.37      0.36       487\n",
      "           5       0.37      0.21      0.27       207\n",
      "           6       0.52      0.63      0.57       505\n",
      "           7       0.53      0.20      0.29        81\n",
      "           8       0.32      0.18      0.23       249\n",
      "           9       0.37      0.33      0.35       324\n",
      "          10       0.51      0.40      0.45       507\n",
      "          11       0.62      0.76      0.68       431\n",
      "          12       0.57      0.30      0.39        80\n",
      "          13       0.43      0.41      0.42       499\n",
      "          14       0.44      0.09      0.14        82\n",
      "          15       0.53      0.73      0.61       476\n",
      "          16       0.59      0.56      0.57       477\n",
      "          17       0.57      0.16      0.25       142\n",
      "          18       0.55      0.62      0.59       499\n",
      "          19       0.37      0.24      0.29       259\n",
      "          20       0.58      0.82      0.68      1021\n",
      "          21       0.30      0.14      0.19       250\n",
      "          22       0.57      0.72      0.63       276\n",
      "          23       0.44      0.53      0.48        87\n",
      "          24       0.47      0.41      0.44       251\n",
      "          25       0.40      0.23      0.29       168\n",
      "          26       0.57      0.55      0.56        83\n",
      "\n",
      "    accuracy                           0.52      8491\n",
      "   macro avg       0.49      0.43      0.43      8491\n",
      "weighted avg       0.50      0.52      0.50      8491\n",
      "\n",
      "[[139   2   6   0   4   0   1   0   0   0   0   1   1   2   0  61  22   1\n",
      "    7   1   4   0  49   3   7   0   0]\n",
      " [  3 139   8   2  34   2   1   0   2   8   2   3   1   6   0  13   7   2\n",
      "    3   0  17   2   2   2   8   0   0]\n",
      " [  3   6 340   0   3   2   3   0   0   0   0   1   0   0   0  14  11   0\n",
      "    1   1   1   0   2   1   5   0   1]\n",
      " [  2   8   4   6   6   4   4   0   0   3   0   2   1   6   0   9   2   0\n",
      "    7   0   7   1   2   2   1   0   0]\n",
      " [  3  39   4   2 178   6  79   0  12  29   9  11   0  30   1   7   4   1\n",
      "   15   5  38   4   1   0   4   4   1]\n",
      " [  3   8  11   1  36  43   7   1   5   3   2   2   3   9   0  11  20   2\n",
      "   10   0   9   0   3   5  11   0   2]\n",
      " [  2   8   2   0  24   1 320   0   8   5   5   6   0   8   0   1   4   1\n",
      "   10   5  64  13   2   3   0   8   5]\n",
      " [  0   2   1   0   9   3   2  16   1   3   1   8   0   4   0   0   1   0\n",
      "   10   2  12   3   0   0   3   0   0]\n",
      " [  0  12   1   0  44   3  22   0  46  13  10   9   1  16   3   0   1   0\n",
      "    4   9  39   8   2   1   2   3   0]\n",
      " [  2   9   1   0  32   5   6   1  15 108  23  19   2  21   1   2   2   0\n",
      "   11   4  54   2   1   1   0   2   0]\n",
      " [  1   4   2   0  18   2  12   2  15  23 205  34   0  44   1   3   1   1\n",
      "   34  27  60   9   2   0   1   6   0]\n",
      " [  2   4   1   1   1   2   2   1   4   9  19 327   0  21   0   4   5   0\n",
      "   11   3  11   2   0   0   1   0   0]\n",
      " [  2   3   1   0   4   3   1   0   1   3   0   3  24   2   0   1   1   0\n",
      "    7   2  10   2   3   1   4   1   1]\n",
      " [  1  15   4   0  32   5  20   4   5  27  34  41   1 205   0  11   5   0\n",
      "   18  12  40   7   0   1   4   6   1]\n",
      " [  0   2   0   0  24   2   5   3   1   8   5   7   0   4   7   1   0   0\n",
      "    1   4   6   2   0   0   0   0   0]\n",
      " [ 32   1   5   1   1   0   1   0   0   1   0   1   0   3   0 346  23   0\n",
      "    5   0   0   0  33   8  15   0   0]\n",
      " [ 35   3  13   0   3   3   0   0   0   2   0   6   0   2   0  79 267   4\n",
      "   16   2  14   0  13   6   9   0   0]\n",
      " [  2   6   5   0   7   2   3   1   0   0   2   3   0   6   0   5  40  23\n",
      "    7   1   4   0   0   6  14   5   0]\n",
      " [  7   2   4   0  15   6  11   0   4   6   8   7   3  10   0  10  14   0\n",
      "  311   6  55   4   9   0   3   2   2]\n",
      " [  0   2   0   0   6   1  10   0   4  11  30  18   0  35   0   1   2   0\n",
      "   12  63  41  14   1   0   0   7   1]\n",
      " [  2   7   4   0  14   3  18   0  12  18  26   8   4  14   2   1   2   0\n",
      "   21  14 833   7   5   1   0   2   3]\n",
      " [  0   5   0   0   8   0  42   1   9   8  17   7   1  23   1   0   1   1\n",
      "   17   6  58  36   0   0   3   5   1]\n",
      " [ 24   0   0   0   0   3   0   0   0   0   0   0   0   1   0  32   1   0\n",
      "    4   0   3   0 198   4   6   0   0]\n",
      " [  3   2   3   0   0   1   0   0   0   0   0   0   0   0   0  10   2   1\n",
      "    2   0   0   0  11  46   6   0   0]\n",
      " [ 16   5   9   0   3   7  13   0   1   1   0   3   0   4   0  33   5   1\n",
      "    5   0  10   3   8  13 103   3   5]\n",
      " [  2   8   3   0   4   3  24   0   1   5   6   2   0   1   0   1   6   2\n",
      "   10   2  31   3   1   1   2  39  11]\n",
      " [  0   1   4   0   1   4   5   0   0   0   0   0   0   2   0   0   3   0\n",
      "    2   1   4   0   0   0   5   5  46]]\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}\")\n",
    "\n",
    "# Classification report and confusion matrix\n",
    "predictions = model.predict(test_generator)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[139   2   6   0   4   0   1   0   0   0   0   1   1   2   0  61  22   1\n",
      "    7   1   4   0  49   3   7   0   0]\n",
      " [  3 139   8   2  34   2   1   0   2   8   2   3   1   6   0  13   7   2\n",
      "    3   0  17   2   2   2   8   0   0]\n",
      " [  3   6 340   0   3   2   3   0   0   0   0   1   0   0   0  14  11   0\n",
      "    1   1   1   0   2   1   5   0   1]\n",
      " [  2   8   4   6   6   4   4   0   0   3   0   2   1   6   0   9   2   0\n",
      "    7   0   7   1   2   2   1   0   0]\n",
      " [  3  39   4   2 178   6  79   0  12  29   9  11   0  30   1   7   4   1\n",
      "   15   5  38   4   1   0   4   4   1]\n",
      " [  3   8  11   1  36  43   7   1   5   3   2   2   3   9   0  11  20   2\n",
      "   10   0   9   0   3   5  11   0   2]\n",
      " [  2   8   2   0  24   1 320   0   8   5   5   6   0   8   0   1   4   1\n",
      "   10   5  64  13   2   3   0   8   5]\n",
      " [  0   2   1   0   9   3   2  16   1   3   1   8   0   4   0   0   1   0\n",
      "   10   2  12   3   0   0   3   0   0]\n",
      " [  0  12   1   0  44   3  22   0  46  13  10   9   1  16   3   0   1   0\n",
      "    4   9  39   8   2   1   2   3   0]\n",
      " [  2   9   1   0  32   5   6   1  15 108  23  19   2  21   1   2   2   0\n",
      "   11   4  54   2   1   1   0   2   0]\n",
      " [  1   4   2   0  18   2  12   2  15  23 205  34   0  44   1   3   1   1\n",
      "   34  27  60   9   2   0   1   6   0]\n",
      " [  2   4   1   1   1   2   2   1   4   9  19 327   0  21   0   4   5   0\n",
      "   11   3  11   2   0   0   1   0   0]\n",
      " [  2   3   1   0   4   3   1   0   1   3   0   3  24   2   0   1   1   0\n",
      "    7   2  10   2   3   1   4   1   1]\n",
      " [  1  15   4   0  32   5  20   4   5  27  34  41   1 205   0  11   5   0\n",
      "   18  12  40   7   0   1   4   6   1]\n",
      " [  0   2   0   0  24   2   5   3   1   8   5   7   0   4   7   1   0   0\n",
      "    1   4   6   2   0   0   0   0   0]\n",
      " [ 32   1   5   1   1   0   1   0   0   1   0   1   0   3   0 346  23   0\n",
      "    5   0   0   0  33   8  15   0   0]\n",
      " [ 35   3  13   0   3   3   0   0   0   2   0   6   0   2   0  79 267   4\n",
      "   16   2  14   0  13   6   9   0   0]\n",
      " [  2   6   5   0   7   2   3   1   0   0   2   3   0   6   0   5  40  23\n",
      "    7   1   4   0   0   6  14   5   0]\n",
      " [  7   2   4   0  15   6  11   0   4   6   8   7   3  10   0  10  14   0\n",
      "  311   6  55   4   9   0   3   2   2]\n",
      " [  0   2   0   0   6   1  10   0   4  11  30  18   0  35   0   1   2   0\n",
      "   12  63  41  14   1   0   0   7   1]\n",
      " [  2   7   4   0  14   3  18   0  12  18  26   8   4  14   2   1   2   0\n",
      "   21  14 833   7   5   1   0   2   3]\n",
      " [  0   5   0   0   8   0  42   1   9   8  17   7   1  23   1   0   1   1\n",
      "   17   6  58  36   0   0   3   5   1]\n",
      " [ 24   0   0   0   0   3   0   0   0   0   0   0   0   1   0  32   1   0\n",
      "    4   0   3   0 198   4   6   0   0]\n",
      " [  3   2   3   0   0   1   0   0   0   0   0   0   0   0   0  10   2   1\n",
      "    2   0   0   0  11  46   6   0   0]\n",
      " [ 16   5   9   0   3   7  13   0   1   1   0   3   0   4   0  33   5   1\n",
      "    5   0  10   3   8  13 103   3   5]\n",
      " [  2   8   3   0   4   3  24   0   1   5   6   2   0   1   0   1   6   2\n",
      "   10   2  31   3   1   1   2  39  11]\n",
      " [  0   1   4   0   1   4   5   0   0   0   0   0   0   2   0   0   3   0\n",
      "    2   1   4   0   0   0   5   5  46]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model_VGG16_lr_1e-6.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class indices saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Save class indices from the train_generator\n",
    "with open('class_indices.json', 'w') as f:\n",
    "    json.dump(train_generator.class_indices, f)\n",
    "\n",
    "print(\"Class indices saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 1s/step - accuracy: 0.4058 - loss: 2.0286\n",
      "Test Accuracy: 0.41\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.50      0.45       311\n",
      "           1       0.38      0.33      0.35       267\n",
      "           2       0.69      0.72      0.70       395\n",
      "           3       1.00      0.04      0.07        77\n",
      "           4       0.24      0.19      0.22       487\n",
      "           5       0.25      0.05      0.09       207\n",
      "           6       0.37      0.47      0.41       505\n",
      "           7       0.67      0.02      0.05        81\n",
      "           8       0.19      0.07      0.10       249\n",
      "           9       0.27      0.16      0.20       324\n",
      "          10       0.38      0.38      0.38       507\n",
      "          11       0.42      0.69      0.52       431\n",
      "          12       0.33      0.10      0.15        80\n",
      "          13       0.33      0.30      0.31       499\n",
      "          14       0.00      0.00      0.00        82\n",
      "          15       0.49      0.62      0.55       476\n",
      "          16       0.43      0.55      0.48       477\n",
      "          17       0.50      0.15      0.23       142\n",
      "          18       0.37      0.48      0.42       499\n",
      "          19       0.42      0.04      0.07       259\n",
      "          20       0.48      0.72      0.58      1021\n",
      "          21       0.24      0.07      0.11       250\n",
      "          22       0.44      0.61      0.51       276\n",
      "          23       0.38      0.40      0.39        87\n",
      "          24       0.28      0.29      0.29       251\n",
      "          25       0.17      0.07      0.09       168\n",
      "          26       0.32      0.27      0.29        83\n",
      "\n",
      "    accuracy                           0.41      8491\n",
      "   macro avg       0.39      0.31      0.30      8491\n",
      "weighted avg       0.39      0.41      0.37      8491\n",
      "\n",
      "[[154   1   3   0   3   1   1   0   0   0   2   8   0   1   0  37  23   1\n",
      "   18   0   4   0  26   5  22   1   0]\n",
      " [ 11  89  12   0  24   1   3   0   1  15   0  11   0  10   0  13  19   0\n",
      "   10   0  23   0  10   3  11   1   0]\n",
      " [  9   2 286   0   2   0   0   0   1   0   1   7   1   4   0  28  29   0\n",
      "    1   1   3   1   8   1   8   1   1]\n",
      " [  4  13   4   3   4   0   4   0   0   3   0   8   0   3   0   6   4   0\n",
      "    7   0   5   0   1   2   6   0   0]\n",
      " [  4  39   7   0  94  10  71   0  11  23  11  33   2  36   0   7  27   1\n",
      "   22   1  54   1   8   2  14   4   5]\n",
      " [ 10   4   9   0  35  11   8   0   0   1   4  19   3  10   0  11  30   0\n",
      "    9   1   9   0   7   7  15   0   4]\n",
      " [  5   9   1   0  25   1 238   0   6   8  16  18   0  27   0   1  18   3\n",
      "   11   1  86   6   3   6   4   5   7]\n",
      " [  0   2   1   0   9   0  11   2   1   4   6   5   0   9   0   0   2   1\n",
      "   12   0  12   1   1   0   1   1   0]\n",
      " [  0   5   0   0  36   2  41   1  18  12  20   9   2  17   0   0   5   0\n",
      "   20   0  46   7   2   0   1   4   1]\n",
      " [  5  13   2   0  28   1   6   0   7  53  28  30   1  25   0   1  11   0\n",
      "   23   3  71   3   2   1   4   6   0]\n",
      " [  3   1   3   0  12   3  26   0   6  14 195  38   0  38   0   5  11   1\n",
      "   43   2  84   7   6   1   2   3   3]\n",
      " [  3   0   2   0   3   1   8   0   3   3  21 298   0  28   0   1  15   0\n",
      "   13   0  23   0   3   0   2   3   1]\n",
      " [  2   1   0   0   2   3   1   0   1   2   3   6   8   1   0   4   0   0\n",
      "    4   0  16   0  14   1   7   0   4]\n",
      " [  7   9   9   0  32   2  32   0   9  21  30  69   1 149   0   3  17   0\n",
      "   20   0  63   6   9   0   5   3   3]\n",
      " [  0   1   0   0  10   0  10   0   4   4   8   9   1  10   0   0   1   0\n",
      "    2   0  14   1   1   1   0   4   1]\n",
      " [ 43   1  25   0   0   0   2   0   0   0   1   8   0   6   0 293  30   0\n",
      "   18   0   0   0  24   2  23   0   0]\n",
      " [ 38   6  22   0   2   2   3   0   0   1   9  10   0   2   0  54 261   8\n",
      "   16   0  14   0   8   1  19   0   1]\n",
      " [  4   5   2   0   4   1   4   0   0   0   2   4   0   5   0  10  44  21\n",
      "    3   0  15   1   2   3   9   1   2]\n",
      " [ 10   4   3   0  10   1  12   0   3   8  23  28   1  10   0   7  21   0\n",
      "  238   3  79   5  26   0   5   1   1]\n",
      " [  0   0   1   0  11   0  26   0   8   5  42  29   0  19   0   2  10   0\n",
      "   30  10  56   3   1   0   3   1   2]\n",
      " [  5  10   5   0  17   1  36   0   3  10  48  25   1  12   0  13  11   0\n",
      "   47   1 734   9  17   2   3   9   2]\n",
      " [  0   4   1   0   9   0  40   0  10   2  18  17   0  23   1   2   2   1\n",
      "   35   0  57  17   2   0   2   6   1]\n",
      " [ 32   0   5   0   2   0   1   0   0   0   1   0   0   0   0  32   1   1\n",
      "   13   0  11   0 167   5   5   0   0]\n",
      " [  5   0   1   0   1   1   0   0   0   0   2   2   0   0   0  13   2   1\n",
      "    0   0   0   0  13  35  11   0   0]\n",
      " [ 18   5  12   0   8   2   8   0   2   2   5   8   2   6   0  48   6   0\n",
      "    7   0  14   2  13  10  73   0   0]\n",
      " [  3  10   0   0   3   0  38   0   1   6  13   5   1   5   0   1   6   3\n",
      "   13   1  30   1   4   4   1  11   8]\n",
      " [  1   1   1   0   1   0  15   0   0   0   9   3   0   0   0   6   2   0\n",
      "    7   0   9   0   3   1   2   0  22]]\n"
     ]
    }
   ],
   "source": [
    "# === Step 8: Evaluate the Model ===\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}\")\n",
    "\n",
    "# Classification report and confusion matrix\n",
    "predictions = model.predict(test_generator)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Learning Rate: 2.499999936844688e-05\n"
     ]
    }
   ],
   "source": [
    "# Get the updated learning rate from the optimizer\n",
    "current_learning_rate = model.optimizer.learning_rate.numpy()\n",
    "print(f\"Current Learning Rate: {current_learning_rate}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min=1e-6, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7348s\u001b[0m 2s/step - accuracy: 0.3710 - loss: 2.0292 - val_accuracy: 0.4029 - val_loss: 2.0702 - learning_rate: 2.5000e-05\n",
      "Epoch 2/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7379s\u001b[0m 2s/step - accuracy: 0.3717 - loss: 2.0209 - val_accuracy: 0.4109 - val_loss: 2.0192 - learning_rate: 2.5000e-05\n",
      "Epoch 3/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7519s\u001b[0m 2s/step - accuracy: 0.3761 - loss: 2.0125 - val_accuracy: 0.4057 - val_loss: 2.0449 - learning_rate: 2.5000e-05\n",
      "Epoch 4/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3769 - loss: 2.0111\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7384s\u001b[0m 2s/step - accuracy: 0.3769 - loss: 2.0111 - val_accuracy: 0.3976 - val_loss: 2.0753 - learning_rate: 2.5000e-05\n",
      "Epoch 5/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7365s\u001b[0m 2s/step - accuracy: 0.3823 - loss: 1.9882 - val_accuracy: 0.4146 - val_loss: 2.0243 - learning_rate: 1.2500e-05\n",
      "Epoch 6/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7412s\u001b[0m 2s/step - accuracy: 0.3879 - loss: 1.9749 - val_accuracy: 0.4217 - val_loss: 1.9908 - learning_rate: 1.2500e-05\n",
      "Epoch 7/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7483s\u001b[0m 2s/step - accuracy: 0.3859 - loss: 1.9812 - val_accuracy: 0.4203 - val_loss: 1.9925 - learning_rate: 1.2500e-05\n",
      "Epoch 8/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3873 - loss: 1.9734\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7495s\u001b[0m 2s/step - accuracy: 0.3873 - loss: 1.9734 - val_accuracy: 0.4239 - val_loss: 1.9984 - learning_rate: 1.2500e-05\n",
      "Epoch 9/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7538s\u001b[0m 2s/step - accuracy: 0.3911 - loss: 1.9680 - val_accuracy: 0.4283 - val_loss: 1.9730 - learning_rate: 6.2500e-06\n",
      "Epoch 10/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7429s\u001b[0m 2s/step - accuracy: 0.3919 - loss: 1.9577 - val_accuracy: 0.4299 - val_loss: 1.9693 - learning_rate: 6.2500e-06\n",
      "Epoch 11/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7410s\u001b[0m 2s/step - accuracy: 0.3915 - loss: 1.9553 - val_accuracy: 0.4277 - val_loss: 1.9786 - learning_rate: 6.2500e-06\n",
      "Epoch 12/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7349s\u001b[0m 2s/step - accuracy: 0.3928 - loss: 1.9547 - val_accuracy: 0.4300 - val_loss: 1.9619 - learning_rate: 6.2500e-06\n",
      "Epoch 13/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7348s\u001b[0m 2s/step - accuracy: 0.3954 - loss: 1.9485 - val_accuracy: 0.4305 - val_loss: 1.9652 - learning_rate: 6.2500e-06\n",
      "Epoch 14/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3944 - loss: 1.9557\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7446s\u001b[0m 2s/step - accuracy: 0.3944 - loss: 1.9557 - val_accuracy: 0.4293 - val_loss: 1.9807 - learning_rate: 6.2500e-06\n",
      "Epoch 15/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7461s\u001b[0m 2s/step - accuracy: 0.3922 - loss: 1.9431 - val_accuracy: 0.4316 - val_loss: 1.9658 - learning_rate: 3.1250e-06\n"
     ]
    }
   ],
   "source": [
    "# === Step 7: Fine-Tune the Model ===\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=2.5e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=15,\n",
    "    callbacks = [reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model_3e-6.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min=1e-6, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7815s\u001b[0m 2s/step - accuracy: 0.3944 - loss: 1.9436 - val_accuracy: 0.4356 - val_loss: 1.9582 - learning_rate: 3.1250e-06\n",
      "Epoch 2/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7690s\u001b[0m 2s/step - accuracy: 0.3964 - loss: 1.9425 - val_accuracy: 0.4315 - val_loss: 1.9613 - learning_rate: 3.1250e-06\n",
      "Epoch 3/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3971 - loss: 1.9369\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7784s\u001b[0m 2s/step - accuracy: 0.3971 - loss: 1.9369 - val_accuracy: 0.4328 - val_loss: 1.9658 - learning_rate: 3.1250e-06\n",
      "Epoch 4/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7723s\u001b[0m 2s/step - accuracy: 0.3961 - loss: 1.9407 - val_accuracy: 0.4333 - val_loss: 1.9615 - learning_rate: 1.5625e-06\n",
      "Epoch 5/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3964 - loss: 1.9374\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7771s\u001b[0m 2s/step - accuracy: 0.3964 - loss: 1.9374 - val_accuracy: 0.4334 - val_loss: 1.9587 - learning_rate: 1.5625e-06\n",
      "Epoch 6/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7642s\u001b[0m 2s/step - accuracy: 0.3959 - loss: 1.9394 - val_accuracy: 0.4318 - val_loss: 1.9624 - learning_rate: 7.8125e-07\n",
      "Epoch 7/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7646s\u001b[0m 2s/step - accuracy: 0.3987 - loss: 1.9355 - val_accuracy: 0.4336 - val_loss: 1.9578 - learning_rate: 7.8125e-07\n",
      "Epoch 8/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7688s\u001b[0m 2s/step - accuracy: 0.3990 - loss: 1.9344 - val_accuracy: 0.4342 - val_loss: 1.9576 - learning_rate: 7.8125e-07\n",
      "Epoch 9/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7567s\u001b[0m 2s/step - accuracy: 0.3973 - loss: 1.9449 - val_accuracy: 0.4326 - val_loss: 1.9553 - learning_rate: 7.8125e-07\n",
      "Epoch 10/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7658s\u001b[0m 2s/step - accuracy: 0.3991 - loss: 1.9307 - val_accuracy: 0.4336 - val_loss: 1.9577 - learning_rate: 7.8125e-07\n",
      "Epoch 11/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3991 - loss: 1.9346\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7672s\u001b[0m 2s/step - accuracy: 0.3991 - loss: 1.9346 - val_accuracy: 0.4326 - val_loss: 1.9573 - learning_rate: 7.8125e-07\n",
      "Epoch 12/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7575s\u001b[0m 2s/step - accuracy: 0.3986 - loss: 1.9384 - val_accuracy: 0.4325 - val_loss: 1.9582 - learning_rate: 3.9062e-07\n",
      "Epoch 13/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3985 - loss: 1.9343\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7564s\u001b[0m 2s/step - accuracy: 0.3985 - loss: 1.9343 - val_accuracy: 0.4334 - val_loss: 1.9590 - learning_rate: 3.9062e-07\n",
      "Epoch 14/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7617s\u001b[0m 2s/step - accuracy: 0.3974 - loss: 1.9377 - val_accuracy: 0.4319 - val_loss: 1.9589 - learning_rate: 1.9531e-07\n",
      "Epoch 15/15\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4008 - loss: 1.9269\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\u001b[1m4276/4276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7704s\u001b[0m 2s/step - accuracy: 0.4008 - loss: 1.9269 - val_accuracy: 0.4345 - val_loss: 1.9563 - learning_rate: 1.9531e-07\n"
     ]
    }
   ],
   "source": [
    "# === Step 7: Fine-Tune the Model ===\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=3.125e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=15,\n",
    "    callbacks = [reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model_1_95e-6.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
